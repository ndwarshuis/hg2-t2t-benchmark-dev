from pathlib import Path
import json

BAMS = {
    "ont": "https://giab-data.s3.amazonaws.com/XY_evaluation/11_16_22_R1041_HG002_UL_Kit14_260_Guppy_6.3.8_sup.pass.lt100kb_sorted_haplotagged.bam",
    "hifi": "https://ftp-trace.ncbi.nlm.nih.gov/ReferenceSamples/giab/data/AshkenazimTrio/HG002_NA24385_son/PacBio_CCS_15kb_20kb_chemistry2/GRCh38/HG002.SequelII.merged_15kb_20kb.pbmm2.GRCh38.haplotag.10x.bam",
}

IDS = list(map(str, [81, 82, 84, 85, 89]))

REGIONS = {
    "IGK": "chr2",
    "TRG": "chr7:0-100000000",
    "TRB": "chr7:100000000",
    "TRA": "chr14:0-80000000",
    "IGH": "chr14:80000000",
    "IGL": "chr22",
}


# wildcard_constraints:
#     gene=f"({'|'.join(GENES)})",


IMGT_URL = "https://www.imgt.org/download/GENE-DB/IMGTGENEDB-ReferenceSequences.fasta-nt-WithoutGaps-F+ORF+allP"

ALIGN_PATH = Path("results") / "immuno_alignments" / "{bamid}"


rule intersect_bam:
    input:
        "static/immuno.bed",
    output:
        ALIGN_PATH / "raw.bam",
    params:
        url=lambda w: BAMS[w.bamid],
    conda:
        "envs/bedtools.yml"
    shell:
        """
        curl -LqSs --fail {params.url} | \
        bedtools intersect -abam stdin -b {input} -ubam -u > {output}
        """


# extra grep -v is to remove a few duplicates that would make downstream steps
# choke
rule download_imgt_goodies:
    output:
        "resources/imgt_human.fa",
    params:
        url=IMGT_URL,
    conda:
        "envs/master.yml"
    shell:
        """
        curl -SsLq --fail {params.url} | \
        seqkit grep -r -n -p '^[A-Z0-9]+\|(TRA|TRB|TRG|TRD|IGH|IGK|IGL).*\|Homo sapiens\|.*' | \
        seqkit grep -v -r -n -p '^K01308\|IGHM\*02\|.*CH2.*$' | \
        seqkit grep -v -r -n -p '^K01309\|IGHM\*02\|.*CH3.*$' \
        > {output}
        """


rule split_igmt_goodies:
    input:
        rules.download_imgt_goodies.output,
    output:
        fa="results/igmt/{locus}.fa",
        header="results/igmt/{locus}_headers.fa",
    script:
        "scripts/split_igmt_db.py"


rule parse_igmt_headers:
    input:
        rules.download_imgt_goodies.output,
    output:
        "results/igmt/headers.tsv",
    shell:
        """
        cat {input} | \
        grep '>' | \
        sed 's/>//' | \
        sed 's/|$//' |
        sed 's/|/\t/g' > {output}
        """


rule index_bam:
    input:
        rules.intersect_bam.output,
    output:
        rules.intersect_bam.output[0] + ".bai",
    conda:
        "envs/master.yml"
    shell:
        """
        samtools index {input}
        """


rule split_bam:
    input:
        _idx=rules.index_bam.output,
        bam=rules.intersect_bam.output,
    output:
        ALIGN_PATH / "split" / "{locus}.fastq",
    params:
        region=lambda w: REGIONS[w.locus],
    conda:
        "envs/master.yml"
    log:
        "log/{bamid}/split/{locus}.log",
    shell:
        """
        samtools view -h {input.bam} {params.region} | \
        samtools fastq > {output} 2> {log}
        """


rule split_fastq:
    input:
        bam=rules.split_bam.output[0],
        alleles=rules.split_igmt_goodies.output.fa,
        motifs="static/flank.fa",
    output:
        fasta=directory(ALIGN_PATH / "split" / "{locus}" / "fasta"),
        sam=directory(ALIGN_PATH / "split" / "{locus}" / "aligned"),
        allele_merged=ALIGN_PATH / "split" / "{locus}" / "allele_merged.bam",
        motif_merged=ALIGN_PATH / "split" / "{locus}" / "motif_merged.bam",
    log:
        allele_index="log/{bamid}/index/{locus}_allele.log",
        motif_index="log/{bamid}/index/{locus}_motif.log",
        allele_align="log/{bamid}/align/{locus}_allele.log",
        motif_align="log/{bamid}/align/{locus}_motif.log",
    threads: 10
    conda:
        "envs/master.yml"
    script:
        "scripts/split_fastq.py"


rule sort_alleles:
    input:
        rules.split_fastq.output.allele_merged
    output:
        ALIGN_PATH / "split" / "{locus}" / "final" / "allele_sorted.bam",
    conda:
        "envs/master.yml"
    shell:
        """
        samtools sort {input} | samtools view -q 30 -b > {output}
        """


rule index_alleles:
    input:
        rules.sort_alleles.output
    output:
        rules.sort_alleles.output[0] + ".bai"
    conda:
        "envs/master.yml"
    shell:
        """
        samtools index {input}
        """


rule cat_fasta:
    input:
        rules.split_fastq.output.fasta
    output:
        ALIGN_PATH / "split" / "{locus}" / "all_reads.fa",
    shell:
        """
        cat {input}/*.fasta > {output}
        """


rule cat_alleles:
    input:
        rules.sort_alleles.output,
    output:
        sam=ALIGN_PATH / "split" / "{locus}" / "all_allele.sam",
        tags=ALIGN_PATH / "split" / "{locus}" / "all_allele.tags",
    conda:
        "envs/master.yml"
    shell:
        """
        samtools view -F 0x4 -F 0x100 {input} | \
        grep -v "SA:" | \
        tee >(cut -f -11 > {output.sam}) | \
        cut -f 12- > {output.tags}
        """


rule cat_motifs:
    input:
        rules.split_fastq.output.motif_merged,
    output:
        ALIGN_PATH / "split" / "{locus}" / "all_motif.sam",
    conda:
        "envs/master.yml"
    shell:
        """
        samtools view {input} | grep -v '^@' > {output}
        """


rule write_alleles_bed:
    input:
        tags=rules.cat_alleles.output.tags,
        sam=rules.cat_alleles.output.sam,
        headers=rules.split_igmt_goodies.output.header,
        order="static/gene_order.tsv",
    output:
        ALIGN_PATH / "split" / "{locus}" / "final" / "allele.bed",
    conda:
        "envs/tidy.yml"
    script:
        "scripts/process_allele.R"


rule write_rss_bed:
    input:
        rules.cat_motifs.output,
    output:
        ALIGN_PATH / "split" / "{locus}" / "final" / "rss.bed",
    conda:
        "envs/tidy.yml"
    script:
        "scripts/process_rss.R"


rule all:
    input:
        expand(
            rules.write_alleles_bed.output + rules.write_rss_bed.output + rules.cat_fasta.output + rules.index_alleles.output,
            locus=REGIONS,
            bamid=["ont"],
        ),
